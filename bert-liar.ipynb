{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.snapshots.pypi/simple/, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.releases.pypi/simple/"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "torchvision 0.5.0 requires torch==1.4.0, but you'll have torch 1.7.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting torch\n",
      "  Downloading torch-1.7.1-cp37-cp37m-win_amd64.whl (184.1 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.5.0-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\i345144\\appdata\\roaming\\python\\python37\\site-packages (from torch) (3.7.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from torch) (1.19.1)\n",
      "Requirement already satisfied: six in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from torchvision) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.7.1 torchvision-0.5.0\n",
      "Looking in indexes: https://pypi.org/simple, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.snapshots.pypi/simple/, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.releases.pypi/simple/\n",
      "Collecting transformers==2.2.0\n",
      "  Using cached transformers-2.2.0-py3-none-any.whl (360 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.16.47-py2.py3-none-any.whl (130 kB)\n",
      "Processing c:\\users\\i345144\\appdata\\local\\pip\\cache\\wheels\\69\\09\\d1\\bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\\sacremoses-0.0.43-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from transformers==2.2.0) (1.19.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from transformers==2.2.0) (4.48.2)\n",
      "Requirement already satisfied: regex in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from transformers==2.2.0) (2020.7.14)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.94-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from requests->transformers==2.2.0) (2020.6.20)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Using cached s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.20.0,>=1.19.47\n",
      "  Downloading botocore-1.19.47-py2.py3-none-any.whl (7.2 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from sacremoses->transformers==2.2.0) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from sacremoses->transformers==2.2.0) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from sacremoses->transformers==2.2.0) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from botocore<1.20.0,>=1.19.47->boto3->transformers==2.2.0) (2.8.1)\n",
      "Installing collected packages: urllib3, chardet, idna, requests, jmespath, botocore, s3transfer, boto3, sacremoses, sentencepiece, transformers\n",
      "Successfully installed boto3-1.16.47 botocore-1.19.47 chardet-4.0.0 idna-2.10 jmespath-0.10.0 requests-2.25.1 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 transformers-2.2.0 urllib3-1.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorlayer 2.2.2 requires cloudpickle>=0.8.1, which is not installed.\n",
      "tensorlayer 2.2.2 requires imageio>=2.5.0, which is not installed.\n",
      "tensorlayer 2.2.2 requires progressbar2>=3.39.3, which is not installed.\n",
      "tensorlayer 2.2.2 requires scikit-image>=0.15.0, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.snapshots.pypi/simple/, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.releases.pypi/simple/\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from seqeval) (0.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16176 sha256=536e3463ba39612af7631ffb10ad894a48df8be15d1474d721edd186dde1d252\n",
      "  Stored in directory: c:\\users\\i345144\\appdata\\local\\pip\\cache\\wheels\\05\\96\\ee\\7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "Looking in indexes: https://pypi.org/simple, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.snapshots.pypi/simple/, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.releases.pypi/simple/\n",
      "Collecting tensorboardx\n",
      "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from tensorboardx) (3.12.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from tensorboardx) (1.19.1)\n",
      "Requirement already satisfied: six in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from tensorboardx) (1.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from protobuf>=3.8.0->tensorboardx) (49.2.1.post20200807)\n",
      "Installing collected packages: tensorboardx\n",
      "Successfully installed tensorboardx-2.1\n",
      "Looking in indexes: https://pypi.org/simple, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.snapshots.pypi/simple/, http://nexus.wdf.sap.corp:8081/nexus/content/groups/build.releases.pypi/simple/\n",
      "Collecting simpletransformers==0.9.1\n",
      "  Downloading simpletransformers-0.9.1-py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (1.5.0)\n",
      "Requirement already satisfied: seqeval in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (1.2.2)\n",
      "Requirement already satisfied: tensorboardx in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (2.25.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (1.19.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (0.23.1)\n",
      "Requirement already satisfied: regex in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (2020.7.14)\n",
      "Requirement already satisfied: tqdm in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from simpletransformers==0.9.1) (4.48.2)\n",
      "Requirement already satisfied: six in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from tensorboardx->simpletransformers==0.9.1) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from tensorboardx->simpletransformers==0.9.1) (3.12.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from requests->simpletransformers==0.9.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from requests->simpletransformers==0.9.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from requests->simpletransformers==0.9.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from requests->simpletransformers==0.9.1) (1.26.2)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from transformers->simpletransformers==0.9.1) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from transformers->simpletransformers==0.9.1) (0.1.94)\n",
      "Requirement already satisfied: boto3 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from transformers->simpletransformers==0.9.1) (1.16.47)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from scikit-learn->simpletransformers==0.9.1) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from scikit-learn->simpletransformers==0.9.1) (0.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers==0.9.1) (49.2.1.post20200807)\n",
      "Requirement already satisfied: click in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from sacremoses->transformers->simpletransformers==0.9.1) (7.1.2)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from boto3->transformers->simpletransformers==0.9.1) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.47 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from boto3->transformers->simpletransformers==0.9.1) (1.19.47)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from boto3->transformers->simpletransformers==0.9.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\i345144\\appdata\\local\\continuum\\anaconda3\\envs\\fakenewsv2\\lib\\site-packages (from botocore<1.20.0,>=1.19.47->boto3->transformers->simpletransformers==0.9.1) (2.8.1)\n",
      "Installing collected packages: simpletransformers\n",
      "Successfully installed simpletransformers-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install transformers==2.2.0\n",
    "!pip install seqeval\n",
    "!pip install tensorboardx\n",
    "!pip install simpletransformers==0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n",
      "PyTorch version:  1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "## Import required libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "#from google.colab import drive \n",
    "import datetime\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn import preprocessing \n",
    "\n",
    "import torch\n",
    "print(\"Cuda available\" if torch.cuda.is_available() is True else \"CPU\")\n",
    "print(\"PyTorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                       date  \\\n",
      "0  18178  2020-03-18T13:26:42-04:00   \n",
      "1   3350  2011-03-04T09:12:59-05:00   \n",
      "2  14343  2017-07-21T11:52:44-04:00   \n",
      "3  15579  2018-07-10T15:52:26-04:00   \n",
      "4   3690  2011-05-04T16:31:24-04:00   \n",
      "\n",
      "                                       speaker  \\\n",
      "0                              Instagram posts   \n",
      "1                                   Glenn Beck   \n",
      "2                                   Mike Pence   \n",
      "3                                     Bloggers   \n",
      "4  National Republican Congressional Committee   \n",
      "\n",
      "                                           statement  \\\n",
      "0         \"COVID-19 started because we eat animals.\"   \n",
      "1  Says Michelle Obama has 43 people on her staff...   \n",
      "2  Says President Donald Trump \"has signed more l...   \n",
      "3  \"US representatives promise implement of UN gu...   \n",
      "4  \"The federal government borrows $4 billion eve...   \n",
      "\n",
      "                                             sources  \\\n",
      "0  ['https://www.cdc.gov/coronavirus/2019-ncov/ca...   \n",
      "1  ['http://www.glennbeck.com/2011/02/25/while-wo...   \n",
      "2  ['https://nrf.com/events/retail-advocates-summ...   \n",
      "3  ['https://conservativedailypost.com/us-represe...   \n",
      "4  ['http://www.politifact.com/georgia/statements...   \n",
      "\n",
      "                             paragraph_based_content  \\\n",
      "0  ['Vegan Instagram users are pinning the 2019 c...   \n",
      "1  ['Glenn Beck rekindled a falsehood about the s...   \n",
      "2  ['Vice President Mike Pence says that when it ...   \n",
      "3  ['A conservative website falsely claimed that ...   \n",
      "4  ['Hundreds of Rhode Islanders got phone calls ...   \n",
      "\n",
      "                              fullText_based_content   label-liar  \n",
      "0  Vegan Instagram users are pinning the 2019 cor...  barely-true  \n",
      "1  Glenn Beck rekindled a falsehood about the siz...   pants-fire  \n",
      "2  Vice President Mike Pence says that when it co...    half-true  \n",
      "3  A conservative website falsely claimed that U....  barely-true  \n",
      "4  Hundreds of Rhode Islanders got phone calls la...  mostly-true  \n",
      "                                           statement   label-liar\n",
      "0         \"covid-19 started because we eat animals.\"  barely-true\n",
      "1  says michelle obama has 43 people on her staff...   pants-fire\n",
      "2  says president donald trump \"has signed more l...    half-true\n",
      "3  \"us representatives promise implement of un gu...  barely-true\n",
      "4  \"the federal government borrows $4 billion eve...  mostly-true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    " \n",
    "## dataset-2\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "train=pd.read_csv('./Dataset_3/FNID-dataset/dataset/fake_news_detection(LIAR)/liar_train.csv')\n",
    "test=pd.read_csv('./Dataset_3/FNID-dataset/dataset/fake_news_detection(LIAR)/liar_test.csv')\n",
    "val=pd.read_csv('./Dataset_3/FNID-dataset/dataset/fake_news_detection(LIAR)/liar_dev.csv')\n",
    "\n",
    "print(train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            statement  label-liar\n",
      "7   \"the united states is the only industrialized ...           1\n",
      "8   \"hillary's main extracurricular activity in la...           0\n",
      "9     says ohio gov. john kasich is \"very unpopular.\"           0\n",
      "14  \"if we make no changes over the next 10 years,...           1\n",
      "17  \"while mayor kenney personally doesn't support...           0\n",
      "5330\n",
      "457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_df = train[['statement', 'label-liar']]\n",
    "eval_df = test[['statement', 'label-liar']]\n",
    "\n",
    "train_df['statement'] = train_df['statement'].str.lower()\n",
    "eval_df['statement'] = eval_df['statement'].str.lower()\n",
    "\n",
    "train_df=train_df[train_df['label-liar'].isin(['true','false'])]\n",
    "eval_df=eval_df[eval_df['label-liar'].isin(['true','false'])]\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "train_df['label-liar']= label_encoder.fit_transform(train_df['label-liar'])\n",
    "eval_df['label-liar']= label_encoder.fit_transform(eval_df['label-liar']) \n",
    "\n",
    "print(train_df.head())\n",
    "print(len(train_df))\n",
    "print(len(eval_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barely-true' 'pants-fire' 'half-true' 'mostly-true' 'true' 'false']\n"
     ]
    }
   ],
   "source": [
    "print(train['label-liar'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15052\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2631\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[train_df['label-liar'].isin(['mostly-true'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[train_df['label-liar'].isin(['pants-fire'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2483\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[train_df['label-liar'].isin(['barely-true'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2833\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[train_df['label-liar'].isin(['half-true'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[train_df['label-liar'].isin(['true'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3280\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[train_df['label-liar'].isin(['false'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            statement label-liar\n",
      "7   \"the united states is the only industrialized ...       true\n",
      "8   \"hillary's main extracurricular activity in la...      false\n",
      "9     says ohio gov. john kasich is \"very unpopular.\"      false\n",
      "14  \"if we make no changes over the next 10 years,...       true\n",
      "17  \"while mayor kenney personally doesn't support...      false\n",
      "5330\n"
     ]
    }
   ],
   "source": [
    "df=train_df[train_df['label-liar'].isin(['true','false'])]\n",
    "print(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbad439286e6491289e2bb35a77cf61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fe9610ac424ed5ad4e4baef29070ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909e95be40f74815bdaf2ae0354ad0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=107.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 0.776913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\transformers\\optimization.py:146: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.686638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.788402\n",
      "\n",
      "Training of xlnet model complete. Saved to outputs/.\n",
      "Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aba4cd46da8403598e440bdb7dd5ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=457.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586c89cc5065452b9309d9849856f0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-aa9bdc26cfed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BERT_prediction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "args = {\n",
    "   'output_dir': 'outputs/',\n",
    "   'cache_dir': 'cache/',\n",
    "\n",
    "   'fp16': False,\n",
    "   'fp16_opt_level': 'O1',\n",
    "   'max_seq_length': 128,\n",
    "   'train_batch_size': 50,\n",
    "   'eval_batch_size': 50,\n",
    "   'gradient_accumulation_steps': 1,\n",
    "   'num_train_epochs': 1,\n",
    "   'weight_decay': 0,\n",
    "   'learning_rate': 1e-3,\n",
    "   'adam_epsilon': 1e-8,\n",
    "   'warmup_ratio': 0.06,\n",
    "   'warmup_steps': 0,\n",
    "   'max_grad_norm': 1.0,\n",
    "\n",
    "   'logging_steps': 50,\n",
    "   'evaluate_during_training': False,\n",
    "   'save_steps': 2000,\n",
    "   'eval_all_checkpoints': True,\n",
    "   'use_tensorboard': True,\n",
    "\n",
    "   'overwrite_output_dir': True,\n",
    "   'reprocess_input_data': True,\n",
    "}\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "model = ClassificationModel('xlnet', 'xlnet-base-cased', args = args, use_cuda=False)\n",
    "\n",
    "model.train_model(train_df)\n",
    "\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
    "print(result, model_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train the model : \n",
      " 7:54:44.673298\n"
     ]
    }
   ],
   "source": [
    "eval_df['BERT_prediction'] = np.argmax(model_outputs, axis = 1)\n",
    "\n",
    "del model\n",
    "del result\n",
    "del model_outputs\n",
    "del wrong_predictions\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "exec_time=end-start\n",
    "print(\"time to train the model : \\n\", exec_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(A, B):\n",
    "    A_name = A.name\n",
    "    B_name = B.name\n",
    "    \n",
    "    df = pd.DataFrame({'A':A,\n",
    "                       'B':B})\n",
    "    df = df.dropna()\n",
    "    A = df['A']\n",
    "    B = df['B']\n",
    "    \n",
    "    acc = accuracy_score(B, A)\n",
    "    f1 = f1_score(B, A)\n",
    "    prec = precision_score(B, A)\n",
    "    rec = recall_score(B, A)\n",
    "    ROC = roc_auc_score(B, A)\n",
    "    \n",
    "    print('Candidate: '+A_name+' | Ground Truth: '+B_name+'\\n')\n",
    "    print('accuracy: %0.2f \\nprecision: %0.2f \\nrecall: %0.2f \\nF1 score: %0.2f \\nROC AUC: %0.2f \\n' % (acc, prec, rec, f1, ROC))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate: BERT_prediction | Ground Truth: label-liar\n",
      "\n",
      "accuracy: 0.54 \n",
      "precision: 0.00 \n",
      "recall: 0.00 \n",
      "F1 score: 0.00 \n",
      "ROC AUC: 0.50 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i345144\\AppData\\Local\\Continuum\\anaconda3\\envs\\FakeNewsV2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report_results( eval_df['BERT_prediction'],eval_df['label-liar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FakeNewsV2",
   "language": "python",
   "name": "fakenewsv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
